{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9.0+cu102\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from torch.utils import data as D\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import random\n",
    "\n",
    "import torchsummary\n",
    "\n",
    "print(torch.__version__)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 기존의 학습 데이터셋은 클래스 별 데이터셋의 개수가 꽤 균형있는 상태임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 수정한 CIFAR 10 datasets (imbalanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Optional, Tuple\n",
    "from PIL import Image\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pickle\n",
    "from torchvision.datasets.vision import VisionDataset\n",
    "from torchvision.datasets.utils import check_integrity, download_and_extract_archive\n",
    "# custom dataset\n",
    "\n",
    "class CIFAR10(VisionDataset):\n",
    "    \"\"\"`CIFAR10 <https://www.cs.toronto.edu/~kriz/cifar.html>`_ Dataset.\n",
    "\n",
    "    Args:\n",
    "        root (string): Root directory of dataset where directory\n",
    "            ``cifar-10-batches-py`` exists or will be saved to if download is set to True.\n",
    "        train (bool, optional): If True, creates dataset from training set, otherwise\n",
    "            creates from test set.\n",
    "        transform (callable, optional): A function/transform that takes in an PIL image\n",
    "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "        target_transform (callable, optional): A function/transform that takes in the\n",
    "            target and transforms it.\n",
    "        download (bool, optional): If true, downloads the dataset from the internet and\n",
    "            puts it in root directory. If dataset is already downloaded, it is not\n",
    "            downloaded again.\n",
    "\n",
    "    \"\"\"\n",
    "    base_folder = 'cifar-10-batches-py'\n",
    "    url = \"https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\"\n",
    "    filename = \"cifar-10-python.tar.gz\"\n",
    "    tgz_md5 = 'c58f30108f718f92721af3b95e74349a'\n",
    "    train_list = [\n",
    "        ['data_batch_1', 'c99cafc152244af753f735de768cd75f'],\n",
    "        ['data_batch_2', 'd4bba439e000b95fd0a9bffe97cbabec'],\n",
    "        ['data_batch_3', '54ebc095f3ab1f0389bbae665268c751'],\n",
    "        ['data_batch_4', '634d18415352ddfa80567beed471001a'],\n",
    "        ['data_batch_5', '482c414d41f54cd18b22e5b47cb7c3cb'],\n",
    "    ]\n",
    "\n",
    "    test_list = [\n",
    "        ['test_batch', '40351d587109b95175f43aff81a1287e'],\n",
    "    ]\n",
    "    meta = {\n",
    "        'filename': 'batches.meta',\n",
    "        'key': 'label_names',\n",
    "        'md5': '5ff9c542aee3614f3951f8cda6e48888',\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False,\n",
    "            imbalanced: bool = False,\n",
    "    ) -> None:\n",
    "\n",
    "        super(CIFAR10, self).__init__(root, transform=transform,\n",
    "                                      target_transform=target_transform)\n",
    "\n",
    "        self.train = train  # training set or test set\n",
    "        \n",
    "        # 추가\n",
    "        self.imbalanced = imbalanced\n",
    "        \n",
    "        if download:\n",
    "            self.download()\n",
    "\n",
    "        if not self._check_integrity():\n",
    "            raise RuntimeError('Dataset not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "\n",
    "        if self.train:\n",
    "            downloaded_list = self.train_list\n",
    "        else:\n",
    "            downloaded_list = self.test_list\n",
    "\n",
    "        self.data: Any = []\n",
    "        self.targets = []\n",
    "\n",
    "        # now load the picked numpy arrays\n",
    "        for file_name, checksum in downloaded_list:\n",
    "            file_path = os.path.join(self.root, self.base_folder, file_name)\n",
    "            with open(file_path, 'rb') as f:\n",
    "                entry = pickle.load(f, encoding='latin1')\n",
    "                self.data.append(entry['data'])\n",
    "                if 'labels' in entry:\n",
    "                    self.targets.extend(entry['labels'])\n",
    "                else:\n",
    "                    self.targets.extend(entry['fine_labels'])\n",
    "\n",
    "        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)\n",
    "        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC\n",
    "\n",
    "        self._load_meta()\n",
    "    \n",
    "        ############################ imbalanced dataset ###############################\n",
    "        if self.train and self.imbalanced:\n",
    "            # print(\"total # of datasets:\", len(self.targets))\n",
    "            \n",
    "            # 목표 : 리스트를 돌면서 1, 3, 5, 7, 9 번 클래스의 개수를 줄인다.\n",
    "            # 방법 : 만약 리스트의 값이 1, 3, 5, 7, 9일 경우 각각 10번 중 9번 삭제\n",
    "            remove_num = [1, 3, 5, 7, 9]\n",
    "            remove_count = [0] * 5\n",
    "\n",
    "            select_idx = [True] * (len(self.data))\n",
    "            # print(select_idx)\n",
    "\n",
    "            for i, target in enumerate(self.targets):\n",
    "                if (target in remove_num) and i % 10 != 0:\n",
    "                    idx = target // 2\n",
    "                    remove_count[idx] += 1\n",
    "                    select_idx[i] = False\n",
    "                    \n",
    "            self.data = self.data[select_idx]\n",
    "            new_targets = []\n",
    "            for i, val in enumerate(select_idx):\n",
    "                if val:\n",
    "                    new_targets.append(self.targets[i])\n",
    "                \n",
    "            self.targets = new_targets\n",
    "        #############################################################################\n",
    "        print(\"# of dataset: \", len(self.data))\n",
    "\n",
    "    def _load_meta(self) -> None:\n",
    "        path = os.path.join(self.root, self.base_folder, self.meta['filename'])\n",
    "        if not check_integrity(path, self.meta['md5']):\n",
    "            raise RuntimeError('Dataset metadata file not found or corrupted.' +\n",
    "                               ' You can use download=True to download it')\n",
    "        with open(path, 'rb') as infile:\n",
    "            data = pickle.load(infile, encoding='latin1')\n",
    "            self.classes = data[self.meta['key']]\n",
    "        self.class_to_idx = {_class: i for i, _class in enumerate(self.classes)}\n",
    "\n",
    "    def __getitem__(self, index: int) -> Tuple[Any, Any]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], self.targets[index]\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def _check_integrity(self) -> bool:\n",
    "        root = self.root\n",
    "        for fentry in (self.train_list + self.test_list):\n",
    "            filename, md5 = fentry[0], fentry[1]\n",
    "            fpath = os.path.join(root, self.base_folder, filename)\n",
    "            if not check_integrity(fpath, md5):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def download(self) -> None:\n",
    "        if self._check_integrity():\n",
    "            print('Files already downloaded and verified')\n",
    "            return\n",
    "        download_and_extract_archive(self.url, self.root, filename=self.filename, md5=self.tgz_md5)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return \"Split: {}\".format(\"Train\" if self.train is True else \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "# of dataset:  27467\n",
      "Files already downloaded and verified\n",
      "# of dataset:  27467\n",
      "Files already downloaded and verified\n",
      "# of dataset:  10000\n"
     ]
    }
   ],
   "source": [
    "# imbalanced paramter를 추가해서 True로 주면 된다.\n",
    "trainset = CIFAR10(root='./data', train=True, download=True, transform=transform, imbalanced=True)\n",
    "validset = CIFAR10(root='./data', train=True, download=True, transform=transform, imbalanced=True)\n",
    "testset = CIFAR10(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train set : 24720\n",
      "# of valid set : 2746\n",
      "# of test set : 10000\n"
     ]
    }
   ],
   "source": [
    "num_train = len(trainset)\n",
    "indices = list(range(num_train))\n",
    "split = int(np.floor(0.1 * num_train))\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_idx, valid_idx = indices[split:], indices[:split] # train 90% valid 10%로 설정\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, sampler=train_sampler, num_workers=0)\n",
    "valid_loader = torch.utils.data.DataLoader(validset, batch_size=batch_size, sampler=valid_sampler, num_workers=0)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"# of train set :\", int(len(trainset) * 0.9))\n",
    "print(\"# of valid set :\", int(len(validset) * 0.1))\n",
    "print(\"# of test set :\", len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "number of plane is 4501\n",
      "number of ship is 4477\n",
      "number of deer is 4542\n",
      "number of frog is 4459\n",
      "number of bird is 4510\n",
      "number of car is 462\n",
      "number of cat is 435\n",
      "number of horse is 420\n",
      "number of truck is 450\n",
      "number of dog is 465\n",
      "\n",
      "\n",
      "total dataset : 24721\n",
      "--------------------------\n",
      "number of cat is  1000\n",
      "number of ship is  1000\n",
      "number of plane is  1000\n",
      "number of frog is  1000\n",
      "number of car is  1000\n",
      "number of truck is  1000\n",
      "number of dog is  1000\n",
      "number of horse is  1000\n",
      "number of deer is  1000\n",
      "number of bird is  1000\n",
      "\n",
      "\n",
      "total dataset : 10000\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "### 클래스 별 개수 확인하기 (training set)\n",
    "print(\"\\n\\n-----------------------------------\\n\\n\")\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "num_class = defaultdict(int)\n",
    "\n",
    "for data in train_loader:\n",
    "    _input, _label = data\n",
    "    \n",
    "    for i in _label:\n",
    "        num_class[classes[i]] += 1\n",
    "    \n",
    "total = 0\n",
    "for cls, num in num_class.items():\n",
    "    total += num\n",
    "    print(f\"number of {cls} is\", num)\n",
    "    \n",
    "print(\"\\n\\ntotal dataset :\", total)\n",
    "print(\"--------------------------\")\n",
    "\n",
    "num_class = defaultdict(int)\n",
    "for data in test_loader:\n",
    "    _input, _label = data\n",
    "    \n",
    "    for i in _label:\n",
    "        num_class[classes[i]] += 1\n",
    "\n",
    "total = 0\n",
    "for cls, num in num_class.items():\n",
    "    total += num\n",
    "    print(f\"number of {cls} is \", num)\n",
    "print(\"\\n\\ntotal dataset :\", total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손실함수(CrossEntropy) 직접 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules import Module\n",
    "from typing import Callable, Optional\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as nn\n",
    "\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "\n",
    "class CrossEntropyLoss(_WeightedLoss):\n",
    "    def __init__(self, weight: Optional[Tensor] = None, size_average=None, ignore_index: int = -100,\n",
    "                 reduce=None, reduction: str = 'mean') -> None:\n",
    "        super(CrossEntropyLoss, self).__init__(weight, size_average, reduce, reduction)\n",
    "        # self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, input: Tensor, target: Tensor) -> Tensor:\n",
    "        def crossEntropyError(input, target):\n",
    "            delta = 1e-7\n",
    "            softmax = torch.nn.Softmax(dim=1)\n",
    "            input = softmax(input)\n",
    "            target = F.one_hot(target, num_classes=10) # target을 원-핫 벡터로 바꾸어주어야 한다. (64, 10)\n",
    "            return -0.1 * torch.sum(target*torch.log(input+delta))\n",
    "        return crossEntropyError(input, target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focal Loss 직접 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules import Module\n",
    "from typing import Callable, Optional\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as nn\n",
    "\n",
    "from torch.nn.modules.loss import _WeightedLoss\n",
    "\n",
    "\n",
    "\n",
    "class FocalLoss(Module):\n",
    "    def __init__(self, gamma=2, alpha=0.1, size_average=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.size_average = size_average\n",
    "        self.softmax = torch.nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        def focalLoss(input, target):\n",
    "            delta = 1e-7\n",
    "            input = self.softmax(input)\n",
    "            target = F.one_hot(target, num_classes=10)\n",
    "            ce = -target* torch.log(input+delta)\n",
    "            weight = (1 - input) ** self.gamma\n",
    "            fl = ce * weight\n",
    "            fl = torch.sum(fl) * self.alpha\n",
    "            return fl\n",
    "        return focalLoss(input, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 직접 구현한 Focal Loss로 학습 돌려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from densenet import *\n",
    "\n",
    "def DenseNetBC_100_12():\n",
    "    return DenseNet(growth_rate=12, num_layers=100, theta=0.5, drop_rate=0.2, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "GeForce RTX 2080 SUPER\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.device(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (dense_init): Conv2d(3, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (dense_block_1): DenseBlock(\n",
       "    (bottleneck_layer_0): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(24, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_1): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(36, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_2): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_3): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(60, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_4): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(72, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_5): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(84, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(84, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_6): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_7): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_8): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_9): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_10): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_11): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_12): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_13): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_14): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_15): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transition_layer_1): Transition_layer(\n",
       "    (conv_1x1): bn_relu_conv(\n",
       "      (batch_norm): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(216, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (avg_pool_2x2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (dense_block_2): DenseBlock(\n",
       "    (bottleneck_layer_0): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_1): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_2): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(132, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(132, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_3): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_4): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(156, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(156, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_5): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(168, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(168, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_6): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(180, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(180, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_7): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_8): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(204, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(204, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_9): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(216, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(216, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_10): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(228, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(228, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_11): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(240, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_12): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(252, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(252, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_13): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(264, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(264, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_14): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(276, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(276, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_15): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (transition_layer_2): Transition_layer(\n",
       "    (conv_1x1): bn_relu_conv(\n",
       "      (batch_norm): BatchNorm2d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv): Conv2d(300, 150, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "    (avg_pool_2x2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (dense_block_3): DenseBlock(\n",
       "    (bottleneck_layer_0): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(150, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(150, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_1): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(162, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(162, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_2): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(174, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(174, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_3): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(186, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(186, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_4): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(198, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(198, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_5): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(210, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(210, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_6): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(222, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(222, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_7): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(234, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(234, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_8): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(246, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(246, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_9): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(258, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(258, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_10): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(270, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(270, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_11): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(282, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(282, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_12): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(294, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(294, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_13): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(306, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(306, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_14): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(318, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(318, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_layer_15): bottleneck_layer(\n",
       "      (conv_1x1): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(330, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(330, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      )\n",
       "      (conv_3x3): bn_relu_conv(\n",
       "        (batch_norm): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv): Conv2d(48, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_layer): Linear(in_features=342, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n",
    "\n",
    "net = DenseNetBC_100_12()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# criterion = CrossEntropyLoss()\n",
    "criterion = FocalLoss(alpha=0.1, gamma=3)\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 30 epoch만 돌고 test 해보기\n",
    "\n",
    "* 1. CE를 사용하여 학습하여 best_model을 cifar_net_imbalanced_CE.pth 로 저장한다.\n",
    "* 2. FL를 사용하여 학습하여 best_model을 cifar_net_imbalanced_FL.path로 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:13,  8.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 6.244209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:25,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   200] loss: 4.882556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:37,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   300] loss: 4.481242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:48,  7.97it/s]\n",
      "43it [00:01, 23.46it/s]\n",
      "1it [00:00,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[1 epoch] Accuracy of the network on the validation images: 50 %\n",
      "best at 1epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   100] loss: 3.969446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:24,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   200] loss: 3.755876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:36,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   300] loss: 3.552696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:46,  8.38it/s]\n",
      "43it [00:01, 24.70it/s]\n",
      "1it [00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[2 epoch] Accuracy of the network on the validation images: 59 %\n",
      "best at 2epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   100] loss: 3.153181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:24,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   200] loss: 3.049306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3,   300] loss: 2.943657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:46,  8.39it/s]\n",
      "43it [00:01, 25.07it/s]\n",
      "1it [00:00,  7.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[3 epoch] Accuracy of the network on the validation images: 67 %\n",
      "best at 3epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   100] loss: 2.703137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:23,  8.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   200] loss: 2.630320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4,   300] loss: 2.594398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:46,  8.40it/s]\n",
      "43it [00:01, 25.09it/s]\n",
      "1it [00:00,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[4 epoch] Accuracy of the network on the validation images: 67 %\n",
      "best at 4epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   100] loss: 2.401752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:23,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   200] loss: 2.318091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5,   300] loss: 2.177737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:45,  8.42it/s]\n",
      "43it [00:01, 25.03it/s]\n",
      "1it [00:00,  7.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[5 epoch] Accuracy of the network on the validation images: 68 %\n",
      "best at 5epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   100] loss: 2.149215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:24,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   200] loss: 2.071226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6,   300] loss: 1.999212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:46,  8.39it/s]\n",
      "43it [00:01, 25.03it/s]\n",
      "1it [00:00,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[6 epoch] Accuracy of the network on the validation images: 70 %\n",
      "best at 6epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   100] loss: 1.885895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:23,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   200] loss: 1.858661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   300] loss: 1.803828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:45,  8.42it/s]\n",
      "43it [00:01, 24.91it/s]\n",
      "1it [00:00,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[7 epoch] Accuracy of the network on the validation images: 72 %\n",
      "best at 7epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   100] loss: 1.659411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:23,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   200] loss: 1.766053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   300] loss: 1.713484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:45,  8.42it/s]\n",
      "43it [00:01, 25.07it/s]\n",
      "1it [00:00,  7.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[8 epoch] Accuracy of the network on the validation images: 75 %\n",
      "best at 8epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,   100] loss: 1.515993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:23,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,   200] loss: 1.534758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9,   300] loss: 1.624185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:45,  8.42it/s]\n",
      "43it [00:01, 25.03it/s]\n",
      "1it [00:00,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[9 epoch] Accuracy of the network on the validation images: 77 %\n",
      "best at 9epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   100] loss: 1.394664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:23,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   200] loss: 1.473050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   300] loss: 1.468419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:45,  8.42it/s]\n",
      "43it [00:01, 25.03it/s]\n",
      "1it [00:00,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 epoch] Accuracy of the network on the validation images: 77 %\n",
      "best at 9epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,   100] loss: 1.255918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:23,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,   200] loss: 1.375932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11,   300] loss: 1.387088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:46,  8.41it/s]\n",
      "43it [00:01, 25.05it/s]\n",
      "1it [00:00,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 epoch] Accuracy of the network on the validation images: 76 %\n",
      "best at 9epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,   100] loss: 1.131557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:23,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,   200] loss: 1.176889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12,   300] loss: 1.238198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:45,  8.42it/s]\n",
      "43it [00:01, 25.00it/s]\n",
      "1it [00:00,  7.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[12 epoch] Accuracy of the network on the validation images: 79 %\n",
      "best at 12epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13,   100] loss: 1.067477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:23,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13,   200] loss: 1.076218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13,   300] loss: 1.089245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:45,  8.42it/s]\n",
      "43it [00:01, 24.92it/s]\n",
      "1it [00:00,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13 epoch] Accuracy of the network on the validation images: 78 %\n",
      "best at 12epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,   100] loss: 1.087828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:24,  8.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,   200] loss: 0.984299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,   300] loss: 1.074105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:46,  8.39it/s]\n",
      "43it [00:01, 25.02it/s]\n",
      "1it [00:00,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14 epoch] Accuracy of the network on the validation images: 79 %\n",
      "best at 12epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15,   100] loss: 0.924886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:23,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15,   200] loss: 0.891654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15,   300] loss: 0.898451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:45,  8.42it/s]\n",
      "43it [00:01, 24.85it/s]\n",
      "1it [00:00,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[15 epoch] Accuracy of the network on the validation images: 81 %\n",
      "best at 15epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:12,  8.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,   100] loss: 0.800796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:23,  8.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,   200] loss: 0.900947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:35,  8.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,   300] loss: 0.883961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:45,  8.41it/s]\n",
      "43it [00:01, 24.42it/s]\n",
      "1it [00:00,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16 epoch] Accuracy of the network on the validation images: 80 %\n",
      "best at 15epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17,   100] loss: 0.780412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17,   200] loss: 0.751868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17,   300] loss: 0.788886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.81it/s]\n",
      "43it [00:01, 25.65it/s]\n",
      "1it [00:00,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17 epoch] Accuracy of the network on the validation images: 80 %\n",
      "best at 15epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,   100] loss: 0.681429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,   200] loss: 0.676332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18,   300] loss: 0.703977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.83it/s]\n",
      "43it [00:01, 25.62it/s]\n",
      "1it [00:00,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[18 epoch] Accuracy of the network on the validation images: 81 %\n",
      "best at 18epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19,   100] loss: 0.626695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19,   200] loss: 0.652852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19,   300] loss: 0.660757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.83it/s]\n",
      "43it [00:01, 25.55it/s]\n",
      "1it [00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[19 epoch] Accuracy of the network on the validation images: 81 %\n",
      "best at 19epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20,   100] loss: 0.573365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20,   200] loss: 0.681166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20,   300] loss: 0.610154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.82it/s]\n",
      "43it [00:01, 25.65it/s]\n",
      "1it [00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 epoch] Accuracy of the network on the validation images: 80 %\n",
      "best at 19epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21,   100] loss: 0.520393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21,   200] loss: 0.586088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21,   300] loss: 0.609614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.83it/s]\n",
      "43it [00:01, 25.55it/s]\n",
      "1it [00:00,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21 epoch] Accuracy of the network on the validation images: 81 %\n",
      "best at 19epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  8.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22,   100] loss: 0.465367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22,   200] loss: 0.550987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22,   300] loss: 0.573560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.82it/s]\n",
      "43it [00:01, 25.57it/s]\n",
      "1it [00:00,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[22 epoch] Accuracy of the network on the validation images: 82 %\n",
      "best at 22epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  8.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23,   100] loss: 0.439773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  9.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23,   200] loss: 0.475490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23,   300] loss: 0.488963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.80it/s]\n",
      "43it [00:01, 25.10it/s]\n",
      "1it [00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[23 epoch] Accuracy of the network on the validation images: 82 %\n",
      "best at 23epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  8.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24,   100] loss: 0.429822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  8.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24,   200] loss: 0.410996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24,   300] loss: 0.497384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.81it/s]\n",
      "43it [00:01, 25.62it/s]\n",
      "1it [00:00,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24 epoch] Accuracy of the network on the validation images: 82 %\n",
      "best at 23epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  9.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25,   100] loss: 0.520616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25,   200] loss: 0.444433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25,   300] loss: 0.435069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.81it/s]\n",
      "43it [00:01, 25.56it/s]\n",
      "1it [00:00,  7.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[25 epoch] Accuracy of the network on the validation images: 83 %\n",
      "best at 25epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26,   100] loss: 0.357293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26,   200] loss: 0.394742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26,   300] loss: 0.370848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.82it/s]\n",
      "43it [00:01, 25.60it/s]\n",
      "1it [00:00,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26 epoch] Accuracy of the network on the validation images: 82 %\n",
      "best at 25epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27,   100] loss: 0.315464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27,   200] loss: 0.348765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27,   300] loss: 0.430020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.80it/s]\n",
      "43it [00:01, 25.66it/s]\n",
      "1it [00:00,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27 epoch] Accuracy of the network on the validation images: 82 %\n",
      "best at 25epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28,   100] loss: 0.354665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  8.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28,   200] loss: 0.298846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28,   300] loss: 0.377996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.83it/s]\n",
      "43it [00:01, 25.58it/s]\n",
      "1it [00:00,  7.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[28 epoch] Accuracy of the network on the validation images: 83 %\n",
      "best at 28epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29,   100] loss: 0.268088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  8.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29,   200] loss: 0.266352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29,   300] loss: 0.335705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.83it/s]\n",
      "43it [00:01, 25.53it/s]\n",
      "1it [00:00,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[29 epoch] Accuracy of the network on the validation images: 83 %\n",
      "best at 29epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [00:11,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30,   100] loss: 0.285053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [00:22,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30,   200] loss: 0.296396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "301it [00:34,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30,   300] loss: 0.298741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:43,  8.82it/s]\n",
      "43it [00:01, 25.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n",
      "[30 epoch] Accuracy of the network on the validation images: 84 %\n",
      "best at 30epoch\n",
      "학습 끝\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "loss_list = []\n",
    "best_accuracy = 0\n",
    "best_epoch = 0\n",
    "accuracy_list = []\n",
    "for epoch in range(30):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for i, data in tqdm(enumerate(train_loader, 0)):\n",
    "        #print(i)\n",
    "        #print(len(train_loader))\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # gradient 매개변수를 0으로 만든다.\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 순전파 + 역전파 + 최적화를 한 후\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        # print(\"loss:\", loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 100 == 99:\n",
    "            print('[%d, %5d] loss: %3f' % (epoch + 1, i + 1, running_loss / 100))\n",
    "            loss_list.append(running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "    # validation part\n",
    "    # validation 과정에서는 balanced dataset을 활용하는 것이 좋을듯! test_laoder 사용\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, data in tqdm(enumerate(valid_loader, 0)):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = net(inputs)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        \n",
    "    # best model을 저장하도록 설정\n",
    "    if best_accuracy <= (100. * correct / total):\n",
    "        best_epoch = epoch + 1\n",
    "        best_accuracy = (100 * correct / total)\n",
    "        PATH = './cifar_net_imbalanced_FL3.pth'\n",
    "        torch.save(net.state_dict(), PATH)\n",
    "        print(\"model saved\")\n",
    "        \n",
    "    print('[%d epoch] Accuracy of the network on the validation images: %d %%' % \n",
    "          (epoch + 1, 100 * correct / total))\n",
    "    accuracy_list.append(100 * correct / total)\n",
    "    \n",
    "    print('best at {}epoch'.format(best_epoch))\n",
    "    \n",
    "    \n",
    "\n",
    "print(\"학습 끝\")\n",
    "print(\"\\n\\n\\n\")\n",
    "plt.plot([i for i in range(1, 31)], accuracy_list)\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "CE_PATH = './cifar_net_imbalanced_CE2.pth'\n",
    "FL_PATH = './cifar_net_imbalanced_FL3.pth'\n",
    "# torch.save(net.state_dict(), FL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test (Focal Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:03,  3.43s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 8.00 GiB total capacity; 2.44 GiB already allocated; 0 bytes free; 2.52 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5f22e494e9f0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\youngju\\3학년 여름방학\\AIMentoring\\densenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[0mdense_init_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mdense_block_1_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdense_block_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdense_init_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[0mtransition_layer_1_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransition_layer_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdense_block_1_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\youngju\\3학년 여름방학\\AIMentoring\\densenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mbottleneck_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottleneck_layer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_rate\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[0mbottleneck_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottleneck_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 139\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    140\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\youngju\\3학년 여름방학\\AIMentoring\\densenet.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[0mused\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnormalization\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32min\u001b[0m \u001b[0meval\u001b[0m \u001b[0mmode\u001b[0m \u001b[0mwhen\u001b[0m \u001b[0mbuffers\u001b[0m \u001b[0mare\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \"\"\"\n\u001b[1;32m--> 167\u001b[1;33m         return F.batch_norm(\n\u001b[0m\u001b[0;32m    168\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[1;31m# If buffers are not to be tracked, ensure that they won't be updated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2279\u001b[0m         \u001b[0m_verify_batch_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2280\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2281\u001b[1;33m     return torch.batch_norm(\n\u001b[0m\u001b[0;32m   2282\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2283\u001b[0m     )\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB (GPU 0; 8.00 GiB total capacity; 2.44 GiB already allocated; 0 bytes free; 2.52 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 모델 불러오기\n",
    "net = DenseNetBC_100_12()\n",
    "net.load_state_dict(torch.load(FL_PATH))\n",
    "net.to(device)\n",
    "print(\"load 완료\")\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for i, data in tqdm(enumerate(test_loader, 0)): # 10000장의 balanced data\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print(100 * (correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test (Cross Loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:00, 22.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:06, 24.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.480000000000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# 모델 불러오기\n",
    "net = DenseNetBC_100_12()\n",
    "net.load_state_dict(torch.load(CE_PATH))\n",
    "net.to(device)\n",
    "print(\"load 완료\")\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "for i, data in tqdm(enumerate(test_loader, 0)): # 10000장의 balanced data\n",
    "    inputs, labels = data\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = net(inputs)\n",
    "    \n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    \n",
    "print(100 * (correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3e2cfb4f58ea>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 변화도는 test중이므로 필요하지 않음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# 각 분류에 대한 예측값 계산\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "correct_pred = {classname : 0 for classname in classes}\n",
    "total_pred = {classname : 0 for classname in classes}\n",
    "\n",
    "# 변화도는 test중이므로 필요하지 않음\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        \n",
    "        # 각 분류별로 올바른 예측 수를 모읍니다.\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "            \n",
    "    \n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5s} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
